<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Homotopy Neural Networks - Documentation</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <article class="post">
        <header>
            <h1>Homotopy Neural Networks</h1>
            <p class="subtitle">Categorical and Homotopy-Theoretic Foundations for Deep Learning</p>
        </header>

        <section>
            <h2>Documentation</h2>

            <h3>Blog Posts</h3>
            <ul>
                <li>
                    <a href="index.html"><strong>Neural Networks Are Functors</strong></a>
                    <p>Comprehensive introduction to the categorical foundation. Covers DirectedGraph = Functor ·⇉· → FinSets, network summing functors, semiring homomorphisms for evaluation, and the DNN topos.</p>
                </li>
                <li>
                    <a href="sparse-attention.html"><strong>Sparse Attention as a Graph Problem</strong></a>
                    <p>Executable demonstration showing attention IS a graph. Includes pure Python implementation with one forward pass, conservation law verification, and 75% memory reduction example.</p>
                </li>
            </ul>

            <h3>Software</h3>
            <ul>
                <li>
                    <a href="https://github.com/faezs/homotopy-nn/tree/main/docs/interpretability"><strong>Interpretability Library</strong></a>
                    <p>Python library for neural network interpretability using resource functors. Implements conversion rates ρ<sub>A→B</sub>, measuring homomorphisms, and Theorem 5.6.</p>
                    <pre><code>pip install -e docs/interpretability
python examples/attention_redundancy.py</code></pre>
                </li>
                <li>
                    <a href="https://github.com/faezs/homotopy-nn/blob/main/docs/sparse-attention-demo.py"><strong>Sparse Attention Demo</strong></a>
                    <p>Pure Python demonstration (no dependencies). Run locally:</p>
                    <pre><code>python3 docs/sparse-attention-demo.py</code></pre>
                </li>
            </ul>

            <h3>Formalization</h3>
            <ul>
                <li>
                    <a href="https://github.com/faezs/homotopy-nn/tree/main/src"><strong>Agda Source Code</strong></a>
                    <p>~13,000 lines of type-checked cubical Agda implementing:</p>
                    <ul>
                        <li>Complete formalization of Belfiore & Bennequin (2022) Sections 1-3</li>
                        <li>Marcolli & Manin resource theory and network summing functors</li>
                        <li>First formal proof that feedforward networks have Φ = 0</li>
                    </ul>
                </li>
            </ul>

            <h3>Repository</h3>
            <p>
                <a href="https://github.com/faezs/homotopy-nn"><strong>GitHub: faezs/homotopy-nn</strong></a>
            </p>
        </section>

        <section>
            <h2>Quick Start</h2>

            <h3>Read the Blog</h3>
            <ol>
                <li>Start with <a href="index.html">Neural Networks Are Functors</a></li>
                <li>See the executable demo: <a href="sparse-attention.html">Sparse Attention as a Graph Problem</a></li>
            </ol>

            <h3>Run the Code</h3>
            <pre><code># Clone repository
git clone https://github.com/faezs/homotopy-nn.git
cd homotopy-nn

# Run sparse attention demo (pure Python)
python3 docs/sparse-attention-demo.py

# Install interpretability library
pip install -e docs/interpretability
python docs/interpretability/examples/attention_redundancy.py

# Type-check Agda (requires nix)
nix develop
agda --library-file=./libraries src/Everything.agda</code></pre>
        </section>

        <section>
            <h2>Key Concepts</h2>

            <h3>DirectedGraph = Functor ·⇉· → FinSets</h3>
            <p>Neural networks are functors from the parallel arrows category to finite sets. This gives the complete data of vertices, edges, and their incidence relations.</p>

            <h3>Network Summing Functors Σ<sub>C</sub>(G)</h3>
            <p>Categories of network subgraphs with conservation laws (Kirchhoff). Forward passes are compositions in Σ<sub>C</sub>(G).</p>

            <h3>Semiring Homomorphisms</h3>
            <p>Any φ: Networks → ℝ gives evaluation semantics (parameter count, FLOPs, entropy). These compose correctly: φ(G₁ ∘ G₂) = φ(G₁) * φ(G₂).</p>

            <h3>Resource Theory</h3>
            <p>Conversion rates ρ<sub>A→B</sub> = sup { m/n | n·A ⪰ m·B } quantify redundancy. Theorem 5.6: ρ<sub>A→B</sub> · M(B) ≤ M(A).</p>
        </section>

        <footer>
            <p>Faez Shakil | <a href="https://github.com/faezs/homotopy-nn">GitHub</a> | 2025</p>
        </footer>
    </article>
</body>
</html>
