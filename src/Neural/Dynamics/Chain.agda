{-# OPTIONS --no-import-sorts #-}
{-|
# Section 1.2: Dynamical Objects of Chains

From Belfiore & Bennequin (2022):

> "The simplest architecture of a network is a chain, and the feed-forward
> functioning of the network, when it has learned, corresponds to a covariant
> functor X from the category C₀(Γ) freely generated by the graph to the
> category of sets, Set."

## Computational vs Denotational

This module demonstrates that the categorical approach is **BOTH**:

1. **Denotational** (semantics): Functors X^w, W, X give mathematical meaning
   to the network architecture independent of execution

2. **Computational** (syntax): The functors also describe the actual forward
   propagation computation

3. **Transformational** (dynamics): Natural transformations (like backprop)
   describe how the computation evolves

### The Three Functors:

- **X^w**: Activity functor (for fixed weights w)
  - Objects: Lₖ ↦ Xₖ (set of possible activities at layer k)
  - Morphisms: edge ↦ X^w_{k+1,k}: Xₖ → Xₖ₊₁ (weighted transformation)

- **W = Π**: Weight functor
  - Objects: Lₖ ↦ Πₖ (product of all weights for layers ≥ k)
  - Morphisms: edge ↦ Πₖ₊₁,ₖ: Πₖ → Πₖ₊₁ (forgetting projection)

- **X**: Total dynamics functor (Equation 1.1)
  - Objects: Lₖ ↦ Xₖ × Πₖ (activity-weight pairs)
  - Represents ALL possible functionings for ALL potential weights
-}

module Neural.Dynamics.Chain where

open import 1Lab.Prelude
open import 1Lab.HLevel
open import 1Lab.Path

open import Cat.Base
open import Cat.Functor.Base
open import Cat.Instances.Free
open import Cat.Instances.Graphs
open import Cat.Instances.Sets

open import Data.Nat.Base using (Nat; zero; suc; _+_)
open import Data.Fin.Base using (Fin; fzero; fsuc; weaken; from-nat; Fin-elim; Fin-cases)

{-|
## Chain Graph (Definition)

A chain is a directed acyclic graph where:
- Vertices are numbered 0, 1, ..., n (layers L₀, L₁, ..., Lₙ)
- Edges go from Lₖ to Lₖ₊₁ for k < n (feedforward)
- No other edges (no skip connections, no convergence)

This is the simplest DNN architecture - a Multi-Layer Perceptron (MLP).
-}

record ChainGraph (n : Nat) : Type where
  field
    -- Number of layers is n+1 (L₀ through Lₙ)
    num-layers : Nat
    layers-eq : num-layers ≡ suc n

  -- Vertices: layers {0, 1, ..., n}
  Vertex : Type
  Vertex = Fin num-layers

  -- Edges: connections {(0,1), (1,2), ..., (n-1,n)}
  Edge : Type
  Edge = Fin n  -- k ∈ Fin n represents edge Lₖ → Lₖ₊₁

  -- Source and target functions
  src : Edge → Vertex
  src k = subst Fin (sym layers-eq) (weaken k)  -- Fin n → Fin (suc n) → Fin num-layers

  tgt : Edge → Vertex
  tgt k = subst Fin (sym layers-eq) (fsuc k)  -- Fin n → Fin (suc n) → Fin num-layers

{-|
## Activity Functor X^w (for fixed weights)

**Denotational**: Describes the "meaning" of each layer as a set of possible
neuron activities.

**Computational**: Describes the actual forward propagation computation.

From paper:
> "to a layer Lₖ is associated the set Xₖ of possible activities of
> the population of neurons in Lₖ, to the edge Lₖ ↦→ Lₖ₊₁ is associated
> the map X^w_{k+1,k}: Xₖ → Xₖ₊₁ which corresponds to the learned weights"
-}

module _ {ℓ} (n : Nat) (chain : ChainGraph n) where
  open ChainGraph chain

  -- Activity spaces at each layer (objects of the functor)
  record ActivityFunctor : Type (lsuc ℓ) where
    field
      -- For each layer k, the set of possible activities
      Activity : Vertex → Type ℓ

      -- For each edge k, the weighted transformation
      -- X^w_{k+1,k}: Activity(Lₖ) → Activity(Lₖ₊₁)
      forward : (k : Edge) → Activity (src k) → Activity (tgt k)

      -- Functoriality: composition law (transitive forward propagation)
      -- compose : ∀ {k₁ k₂ k₃} → Path k₁ k₂ → Path k₂ k₃ → ...
      -- (requires free category construction)

  {-|
  ## Weight Functor W = Π

  **Denotational**: Describes the space of all possible network configurations.

  **Computational**: Describes how weights are "forgotten" as we move forward
  through layers.

  From paper:
  > "for Lₖ we define Πₖ as the product of all the sets W_{l+1,l} of weights
  > for l ≥ k, and to the edge k ↦→ k+1 we associate the natural forgetting
  > projection Πₖ₊₁,ₖ: Πₖ → Πₖ₊₁"

  **Key insight**: Weights are morphisms in X^w, but objects in W!
  This is a "dual representation" as noted in the paper.
  -}

  record WeightFunctor : Type (lsuc ℓ) where
    field
      -- Weight space for each edge (individual transformation)
      WeightSpace : Edge → Type ℓ

      -- At layer k: product of all weight spaces for l ≥ k
      -- Πₖ = ∏_{l≥k} W_{l+1,l}
      Π : Vertex → Type ℓ

      -- Forgetting projection: Πₖ → Πₖ₊₁
      -- Forgets the weights W_{k+1,k} when moving from layer k to k+1
      forget : (k : Edge) → Π (src k) → Π (tgt k)

      -- For output layer Lₙ: Πₙ = ★ (terminal object/singleton)
      -- Last vertex is fsuc (fsuc ... fzero) n times = from-nat n
      output-terminal : Π (subst Fin (sym layers-eq) (from-nat n)) ≃ ⊤

  {-|
  ## Crossed Product Functor X (Equation 1.1)

  **This is the key unification**: X represents ALL possible functionings
  of the network for EVERY potential weight configuration.

  From paper (Equation 1.1):
  > "The cartesian products Xₖ × Πₖ together with the maps
  >  X_{k+1,k} × Π_{k+1,k}(xₖ, (w_{k+1,k}, w'_{k+1})) = (X^w_{k+1,k}(xₖ), w'_{k+1})
  > also defines a covariant functor X"

  **Interpretation**:
  - State: (activity at layer k, weights for layers ≥ k)
  - Transition: apply weighted transformation, forget used weights
  - This describes the state evolution of the learning system!
  -}

  record TotalDynamicsFunctor (X^w : ActivityFunctor) (W : WeightFunctor) : Type ℓ where
    open ActivityFunctor X^w
    open WeightFunctor W

    -- At each layer: activity-weight pairs
    State : Vertex → Type ℓ
    State k = Activity k × Π k

    -- Transition function (Equation 1.1)
    -- (xₖ, (wₖ₊₁ₖ, w'ₖ₊₁)) ↦ (X^w_{k+1,k}(xₖ), w'_{k+1})
    transition : (k : Edge) → State (src k) → State (tgt k)
    transition k (xₖ , wₖ) = forward k xₖ , forget k wₖ

    -- Natural projection from X to W
    -- This is a natural transformation: X → W
    proj-weights : ∀ (k : Vertex) → State k → Π k
    proj-weights k (x , w) = w

{-|
## Example: 3-Layer MLP

Let's make this concrete with a simple example:

- L₀: Input layer (2 neurons)
- L₁: Hidden layer (3 neurons)
- L₂: Output layer (1 neuron)

Activities:
- X₀ = ℝ²
- X₁ = ℝ³
- X₂ = ℝ

Weights:
- W₁₀: ℝ² → ℝ³ (6 parameters: 3×2 matrix)
- W₂₁: ℝ³ → ℝ (3 parameters: 1×3 matrix)

Weight functor:
- Π₀ = W₁₀ × W₂₁ (all weights)
- Π₁ = W₂₁ (weights for layers ≥ 1)
- Π₂ = ★ (no more weights)

Forgetting projections:
- Π₀₁: (w₁₀, w₂₁) ↦ w₂₁ (forget first layer weights)
- Π₁₂: w₂₁ ↦ ★ (forget second layer weights)
-}

-- Postulate ℝ for the example (would import from a real analysis library)
postulate
  ℝ : Type
  ℝ-is-set : is-set ℝ

-- Example: 2-layer MLP (input → hidden → output)
module Example-MLP where
  -- Chain with 2 edges (3 layers: L₀, L₁, L₂)
  mlp-chain : ChainGraph 2
  mlp-chain = record
    { num-layers = 3
    ; layers-eq = refl
    }

  -- Activity spaces (concrete definitions as Fin n → ℝ)
  ℝ² : Type
  ℝ² = Fin 2 → ℝ

  ℝ³ : Type
  ℝ³ = Fin 3 → ℝ

  ℝ¹ : Type
  ℝ¹ = Fin 1 → ℝ

  -- Weight spaces (matrices as Fin m → Fin n → ℝ)
  Matrix-2×3 : Type
  Matrix-2×3 = Fin 2 → Fin 3 → ℝ  -- 2 input dims, 3 output dims

  Matrix-3×1 : Type
  Matrix-3×1 = Fin 3 → Fin 1 → ℝ  -- 3 input dims, 1 output dim

  -- Matrix-vector multiplication (requires summing)
  -- For now we postulate sum (would come from a linear algebra library)
  postulate
    sum : {n : Nat} → (Fin n → ℝ) → ℝ
    _*ᵣ_ : ℝ → ℝ → ℝ

  -- Weighted transformations (concrete matrix-vector multiplication)
  apply-w₁₀ : Matrix-2×3 → ℝ² → ℝ³
  apply-w₁₀ W x j = sum (λ i → W i j *ᵣ x i)

  apply-w₂₁ : Matrix-3×1 → ℝ³ → ℝ¹
  apply-w₂₁ W x j = sum (λ i → W i j *ᵣ x i)

  -- Open the mlp-chain module to access src and tgt
  open ChainGraph mlp-chain

  -- Helper functions for Activity functor
  mlp-activity-space : Fin 3 → Type
  mlp-activity-space = Fin-elim (λ _ → Type)
                         ℝ²  -- fzero case
                         (λ k _ → Fin-elim (λ _ → Type) ℝ³ (λ _ _ → ℝ¹) k)  -- fsuc case

  mlp-forward : (w₁₀ : Matrix-2×3) → (w₂₁ : Matrix-3×1) → (e : Fin 2) →
                mlp-activity-space (src e) →
                mlp-activity-space (tgt e)
  mlp-forward w₁₀ w₂₁ = Fin-cases
    {P = λ e → mlp-activity-space (src e) → mlp-activity-space (tgt e)}
    (apply-w₁₀ w₁₀)      -- P 0 case (edge 0: L₀ → L₁)
    (λ _ → apply-w₂₁ w₂₁)  -- P (fsuc x) case (edge 1: L₁ → L₂)

  -- Concrete Activity functor for the MLP
  mlp-activity : Matrix-2×3 → Matrix-3×1 → ActivityFunctor 2 mlp-chain
  mlp-activity w₁₀ w₂₁ = record
    { Activity = mlp-activity-space
    ; forward = mlp-forward w₁₀ w₂₁
    }

  -- Helper functions for Weight functor
  mlp-weight-space : Fin 2 → Type
  mlp-weight-space = Fin-elim (λ _ → Type) Matrix-2×3 (λ _ _ → Matrix-3×1)

  mlp-weight-product : Fin 3 → Type
  mlp-weight-product = Fin-elim (λ _ → Type)
                         (Matrix-2×3 × Matrix-3×1)  -- fzero case
                         (λ k _ → Fin-elim (λ _ → Type) Matrix-3×1 (λ _ _ → ⊤) k)  -- fsuc case

  mlp-forget : (e : Fin 2) → mlp-weight-product (src e) →
                             mlp-weight-product (tgt e)
  mlp-forget = Fin-cases
    {P = λ e → mlp-weight-product (src e) → mlp-weight-product (tgt e)}
    snd              -- P 0 case: (W₁₀ × W₂₁) → W₂₁
    (λ _ _ → tt)     -- P (fsuc x) case: W₂₁ → ⊤

  -- Concrete Weight functor for the MLP
  mlp-weights : WeightFunctor 2 mlp-chain
  mlp-weights = record
    { WeightSpace = mlp-weight-space
    ; Π = mlp-weight-product
    ; forget = mlp-forget
    ; output-terminal = id-equiv
    }

{-|
## Computational vs Denotational: The Answer

The categorical approach is **BOTH**:

1. **Denotational Semantics**: The functors X^w, W, X give the *meaning*
   of the network architecture. They describe what each layer *is* (a set
   of possible states) and what each edge *means* (a transformation).
   This is independent of any particular execution.

2. **Computational Semantics**: The same functors also describe the
   *computation* during forward propagation. Following arrows in the
   category is literally computing the forward pass.

3. **Dynamic Semantics**: Natural transformations (like backpropagation
   in Section 1.4) describe how the system *evolves* during learning.

**The power**: By using category theory, we get a unified framework where:
- The graph Γ is the **syntax** (network architecture)
- The functors are the **semantics** (what it means)
- Natural transformations are the **dynamics** (how it changes)
- The topos C^ captures the **logic** of the network

This is why the paper says (Section 1.2):
> "It is remarkable that, in supervised learning, the Backpropagation
> algorithm is represented by a flow of natural transformations of the
> functor W to itself."

Backpropagation is NOT just an algorithm - it's a natural transformation!
-}
